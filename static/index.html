<!DOCTYPE html>
<html lang="ja">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>Voice Coach</title>
<style>
  * { box-sizing: border-box; margin: 0; padding: 0; }
  body {
    font-family: -apple-system, sans-serif;
    background: #1a1a2e;
    color: #eee;
    display: flex;
    justify-content: center;
    align-items: center;
    min-height: 100vh;
  }
  .container { text-align: center; max-width: 520px; width: 100%; padding: 1rem; }

  /* VRM Canvas */
  #avatar-canvas {
    width: 100%;
    height: 400px;
    border-radius: 12px;
    background: #16213e;
  }
  #loading-overlay {
    position: relative;
    top: -220px;
    color: #666;
    font-size: 0.9rem;
    pointer-events: none;
  }

  /* State badge */
  .state-badge {
    margin-top: 0.8rem;
    display: inline-flex;
    align-items: center;
    gap: 0.4rem;
    font-size: 0.85rem;
    padding: 0.3rem 0.8rem;
    border-radius: 999px;
    background: rgba(255,255,255,0.05);
  }
  .state-icon {
    font-size: 1rem;
    line-height: 1;
  }

  /* Button */
  #btn {
    margin-top: 1rem;
    width: 100px;
    height: 100px;
    border-radius: 50%;
    border: none;
    font-size: 0.9rem;
    cursor: pointer;
    transition: all 0.2s;
    background: #e94560;
    color: #fff;
    font-weight: bold;
  }
  #btn:hover:not(:disabled) { transform: scale(1.05); }
  #btn:disabled { opacity: 0.5; cursor: not-allowed; }
  #btn.connected { background: #4ade80; }
  #btn.connected:hover:not(:disabled) { background: #f87171; }
  #btn.connecting { background: #fbbf24; animation: pulse 1s infinite; }
  @keyframes pulse {
    0%,100% { box-shadow: 0 0 0 0 rgba(233,69,96,0.4); }
    50% { box-shadow: 0 0 0 20px rgba(233,69,96,0); }
  }

  /* Transcript */
  #texts { margin-top: 1rem; text-align: left; font-size: 0.9rem; }
  .you, .coach { padding: 0.3rem 0; line-height: 1.5; }
  .you .label { color: #888; }
  .coach .label { color: #e94560; }
</style>
<script type="importmap">
{
  "imports": {
    "three": "https://cdn.jsdelivr.net/npm/three@0.176.0/build/three.module.js",
    "three/addons/": "https://cdn.jsdelivr.net/npm/three@0.176.0/examples/jsm/",
    "@pixiv/three-vrm": "https://cdn.jsdelivr.net/npm/@pixiv/three-vrm@3/lib/three-vrm.module.min.js"
  }
}
</script>
</head>
<body>
<div class="container">
  <canvas id="avatar-canvas"></canvas>
  <div id="loading-overlay">Loading VRM model...</div>
  <div class="state-badge">
    <span class="state-icon" id="state-icon"></span>
    <span id="state-label"></span>
  </div>
  <br>
  <button id="btn">Connect</button>
  <div id="texts"></div>
</div>

<script type="module">
import * as THREE from 'three';
import { GLTFLoader } from 'three/addons/loaders/GLTFLoader.js';
import { VRMLoaderPlugin, VRMUtils } from '@pixiv/three-vrm';

// ===== DOM Elements =====
const canvas = document.getElementById('avatar-canvas');
const loadingOverlay = document.getElementById('loading-overlay');
const stateIcon = document.getElementById('state-icon');
const stateLabel = document.getElementById('state-label');
const btn = document.getElementById('btn');
const textsEl = document.getElementById('texts');

// ===== Shared State =====
let currentVrm = null;

// ===== State Machine =====
const STATES = {
  IDLE:      { label: 'Ready',        icon: '\u25CF', color: '#4ade80' },
  LISTENING: { label: 'Listening...', icon: '\u25C9', color: '#f87171' },
  THINKING:  { label: 'Thinking...', icon: '\u25CC', color: '#fbbf24' },
  SPEAKING:  { label: 'Speaking...',  icon: '\u25B6', color: '#60a5fa' },
  ERROR:     { label: 'Error',        icon: '\u2715', color: '#ef4444' },
};

let currentState = 'IDLE';

function setState(newState, detail) {
  currentState = newState;
  const s = STATES[newState];
  if (!s) return;
  stateIcon.textContent = s.icon;
  stateIcon.style.color = s.color;
  stateLabel.textContent = detail || s.label;
  updateStateExpression(newState);
}

function updateStateExpression(state) {
  if (!currentVrm || !currentVrm.expressionManager) return;
  currentVrm.expressionManager.setValue('neutral', 0);
  currentVrm.expressionManager.setValue('relaxed', 0);
  if (state === 'THINKING') {
    currentVrm.expressionManager.setValue('neutral', 0.3);
  } else if (state === 'IDLE') {
    currentVrm.expressionManager.setValue('relaxed', 0.2);
  }
}

setState('IDLE');

// ===== Three.js Scene =====
const scene = new THREE.Scene();
scene.background = new THREE.Color(0x16213e);

const renderer = new THREE.WebGLRenderer({ canvas, antialias: true });
renderer.setPixelRatio(window.devicePixelRatio);

function resizeCanvas() {
  const w = canvas.parentElement.clientWidth;
  const h = 400;
  canvas.style.width = w + 'px';
  canvas.style.height = h + 'px';
  renderer.setSize(w, h);
  camera.aspect = w / h;
  camera.updateProjectionMatrix();
}

const camera = new THREE.PerspectiveCamera(20, canvas.clientWidth / 400, 0.1, 20);
camera.position.set(0, 1.35, 1.8);
camera.lookAt(0, 1.35, 0);

const dirLight = new THREE.DirectionalLight(0xffffff, 1.0);
dirLight.position.set(1, 2, 3);
scene.add(dirLight);
scene.add(new THREE.AmbientLight(0xffffff, 0.6));

resizeCanvas();
window.addEventListener('resize', resizeCanvas);

// ===== VRM Loading =====
const loader = new GLTFLoader();
loader.register((parser) => new VRMLoaderPlugin(parser));

loader.load(
  '/static/model.vrm',
  (gltf) => {
    const vrm = gltf.userData.vrm;
    VRMUtils.removeUnnecessaryVertices(gltf.scene);
    VRMUtils.removeUnnecessaryJoints(gltf.scene);

    vrm.scene.rotation.y = Math.PI;

    scene.add(vrm.scene);
    currentVrm = vrm;

    const leftUpperArm = vrm.humanoid.getNormalizedBoneNode('leftUpperArm');
    const rightUpperArm = vrm.humanoid.getNormalizedBoneNode('rightUpperArm');
    if (leftUpperArm) leftUpperArm.rotation.z = 1.2;
    if (rightUpperArm) rightUpperArm.rotation.z = -1.2;

    const headNode = vrm.humanoid.getNormalizedBoneNode('head');
    if (headNode) {
      const headPos = new THREE.Vector3();
      headNode.getWorldPosition(headPos);
      camera.position.set(0, headPos.y + 0.02, 1.2);
      camera.lookAt(0, headPos.y - 0.03, 0);
    }

    loadingOverlay.style.display = 'none';
    console.log('VRM loaded. Available expressions:',
      vrm.expressionManager ? Object.keys(vrm.expressionManager._expressionMap || {}) : 'none');
  },
  (progress) => {
    if (progress.total > 0) {
      const pct = Math.round(progress.loaded / progress.total * 100);
      loadingOverlay.textContent = `Loading VRM model... ${pct}%`;
    }
  },
  (error) => {
    console.error('VRM load error:', error);
    loadingOverlay.textContent = 'VRM model not found. Place model.vrm in static/';
  }
);

// ===== Lip Sync Engine =====
const VISEME_MAP = {
  'A': 'aa', 'I': 'ih', 'U': 'ou', 'E': 'ee', 'O': 'oh', 'N': null
};
const MOUTH_EXPRESSIONS = ['aa', 'ih', 'ou', 'ee', 'oh'];
const VOICED_INTENSITY = 0.8;
const UNVOICED_INTENSITY = 0.3;

const lipSync = {
  active: false,
  visemes: [],
  startTime: 0,
  currentIndex: 0,
};

function startLipSync(visemes) {
  lipSync.active = true;
  lipSync.visemes = visemes;
  lipSync.startTime = performance.now() / 1000;
  lipSync.currentIndex = 0;
}

function stopLipSync() {
  lipSync.active = false;
  if (currentVrm && currentVrm.expressionManager) {
    for (const expr of MOUTH_EXPRESSIONS) {
      currentVrm.expressionManager.setValue(expr, 0);
    }
  }
}

function getLipSyncElapsed() {
  return performance.now() / 1000 - lipSync.startTime;
}

function updateLipSync() {
  if (!lipSync.active || !currentVrm || !currentVrm.expressionManager) return;

  const elapsed = getLipSyncElapsed();
  const visemes = lipSync.visemes;

  while (
    lipSync.currentIndex < visemes.length - 1 &&
    visemes[lipSync.currentIndex + 1].t <= elapsed
  ) {
    lipSync.currentIndex++;
  }

  if (lipSync.currentIndex >= visemes.length) {
    stopLipSync();
    return;
  }

  const v = visemes[lipSync.currentIndex];

  for (const expr of MOUTH_EXPRESSIONS) {
    currentVrm.expressionManager.setValue(expr, 0);
  }

  if (elapsed >= v.t && elapsed <= v.t + v.dur) {
    const target = VISEME_MAP[v.v];
    const intensity = v.unvoiced ? UNVOICED_INTENSITY : VOICED_INTENSITY;

    const progress = (elapsed - v.t) / v.dur;
    let envelope;
    if (progress < 0.15) {
      envelope = progress / 0.15;
    } else if (progress > 0.85) {
      envelope = (1.0 - progress) / 0.15;
    } else {
      envelope = 1.0;
    }

    const value = intensity * Math.max(0, envelope);

    if (target) {
      currentVrm.expressionManager.setValue(target, value);
    }

    const COARTIC_BLEND = 0.15;
    if (progress > 0.7 && lipSync.currentIndex < visemes.length - 1) {
      const nextV = visemes[lipSync.currentIndex + 1];
      const nextTarget = VISEME_MAP[nextV.v];
      if (nextTarget && nextTarget !== target) {
        const blend = ((progress - 0.7) / 0.3) * COARTIC_BLEND * intensity;
        currentVrm.expressionManager.setValue(nextTarget, blend);
      }
    }
  }
}

// ===== Blink Animation =====
let blinkTimer = 0;
let blinkPhase = 0;
let blinksRemaining = 0;
let nextBlinkIn = 2 + Math.random() * 4;

function getBlinkInterval() {
  if (currentState === 'THINKING') return 1.2 + Math.random() * 2.0;
  if (currentState === 'SPEAKING') return 2.0 + Math.random() * 3.0;
  return 2.5 + Math.random() * 4.0;
}

function updateBlink(delta) {
  if (!currentVrm || !currentVrm.expressionManager) return;

  blinkTimer += delta;

  if (blinkPhase === 0 && blinkTimer >= nextBlinkIn) {
    blinkPhase = 1;
    blinkTimer = 0;
    if (blinksRemaining <= 0) {
      blinksRemaining = Math.random() < 0.2 ? 2 : 1;
    }
  }

  if (blinkPhase === 1) {
    const v = Math.min(blinkTimer / 0.05, 1.0);
    currentVrm.expressionManager.setValue('blink', v);
    if (v >= 1.0) { blinkPhase = 2; blinkTimer = 0; }
  }

  if (blinkPhase === 2) {
    const v = 1.0 - Math.min(blinkTimer / 0.1, 1.0);
    currentVrm.expressionManager.setValue('blink', v);
    if (v <= 0) {
      blinksRemaining--;
      if (blinksRemaining > 0) {
        blinkPhase = 1;
        blinkTimer = -0.08;
      } else {
        blinkPhase = 0;
        blinkTimer = 0;
        nextBlinkIn = getBlinkInterval();
      }
    }
  }
}

// ===== Idle Breathing & Speaking Nod =====
let animElapsed = 0;

function breathNoise(t) {
  return Math.sin(t * 0.13) * 0.4 + Math.sin(t * 0.21 * 1.618) * 0.3;
}

function updateIdleBreathing(delta) {
  if (!currentVrm) return;
  animElapsed += delta;

  const head = currentVrm.humanoid.getNormalizedBoneNode('head');
  const spine = currentVrm.humanoid.getNormalizedBoneNode('spine');

  if (currentState === 'IDLE' || currentState === 'LISTENING') {
    const noise = breathNoise(animElapsed);
    const spineFreq = 0.8 + noise * 0.15;
    const spineAmp = 0.003 + noise * 0.001;
    const headFreq = 1.0 + noise * 0.1;
    if (spine) spine.rotation.x = Math.sin(animElapsed * spineFreq) * spineAmp;
    if (head) head.rotation.x = Math.sin(animElapsed * headFreq) * 0.002;
    if (head) head.rotation.y = Math.sin(animElapsed * 0.3) * 0.003;
  } else if (currentState === 'SPEAKING' && lipSync.active) {
    const elapsed = getLipSyncElapsed();
    if (head) head.rotation.x = Math.sin(elapsed * 3.5) * 0.015;
    if (head) head.rotation.y = Math.sin(elapsed * 1.8) * 0.008;
    if (spine) spine.rotation.x = Math.sin(elapsed * 2.0) * 0.005;
  } else {
    if (head) { head.rotation.x = 0; head.rotation.y = 0; }
    if (spine) spine.rotation.x = 0;
  }
}

// ===== Animation Loop =====
const clock = new THREE.Clock();

function animate() {
  requestAnimationFrame(animate);
  const delta = clock.getDelta();
  if (currentVrm) {
    updateLipSync();
    updateBlink(delta);
    updateIdleBreathing(delta);
    currentVrm.update(delta);
  }
  renderer.render(scene, camera);
}

animate();

// ===== WebSocket Audio Connection =====
let ws = null;
let audioCtx = null;
let micStream = null;
let workletNode = null;
let connected = false;
let pendingVisemes = null;
let currentAudioSource = null;

// AudioWorklet プロセッサ（100ms バッファで PCM を送信）
const PROCESSOR_CODE = `
class PCMCapture extends AudioWorkletProcessor {
  constructor() {
    super();
    this.buffer = new Float32Array(4800);
    this.offset = 0;
  }
  process(inputs) {
    const ch = inputs[0][0];
    if (!ch) return true;
    for (let i = 0; i < ch.length; i++) {
      this.buffer[this.offset++] = ch[i];
      if (this.offset >= 4800) {
        this.port.postMessage(this.buffer.slice(0, 4800));
        this.offset = 0;
      }
    }
    return true;
  }
}
registerProcessor('pcm-capture', PCMCapture);
`;

btn.addEventListener('click', toggleConnection);

async function toggleConnection() {
  if (connected) {
    disconnect();
  } else {
    await connect();
  }
}

async function connect() {
  btn.textContent = 'Connecting';
  btn.classList.add('connecting');
  btn.disabled = true;

  try {
    // マイク取得
    micStream = await navigator.mediaDevices.getUserMedia({ audio: true });

    // AudioContext（48kHz でサーバー VAD と一致させる）
    audioCtx = new AudioContext({ sampleRate: 48000 });

    // AudioWorklet でマイク音声をキャプチャ
    const blob = new Blob([PROCESSOR_CODE], { type: 'application/javascript' });
    const url = URL.createObjectURL(blob);
    await audioCtx.audioWorklet.addModule(url);
    URL.revokeObjectURL(url);

    const source = audioCtx.createMediaStreamSource(micStream);
    workletNode = new AudioWorkletNode(audioCtx, 'pcm-capture');
    source.connect(workletNode);

    // WebSocket 接続
    const protocol = location.protocol === 'https:' ? 'wss:' : 'ws:';
    ws = new WebSocket(`${protocol}//${location.host}/ws/audio`);
    ws.binaryType = 'arraybuffer';

    await new Promise((resolve, reject) => {
      ws.onopen = resolve;
      ws.onerror = reject;
    });

    // マイク音声を int16 PCM で WebSocket 送信
    workletNode.port.onmessage = (e) => {
      if (!ws || ws.readyState !== WebSocket.OPEN) return;
      const float32 = e.data;
      const int16 = new Int16Array(float32.length);
      for (let i = 0; i < float32.length; i++) {
        const s = Math.max(-1, Math.min(1, float32[i]));
        int16[i] = s < 0 ? s * 0x8000 : s * 0x7FFF;
      }
      ws.send(int16.buffer);
    };

    // サーバーからのメッセージ受信
    ws.onmessage = async (e) => {
      if (typeof e.data === 'string') {
        // JSON テキストメッセージ
        const msg = JSON.parse(e.data);

        if (msg.type === 'state') {
          setState(msg.state);

          if (msg.state === 'SPEAKING' && pendingVisemes) {
            startLipSync(pendingVisemes);
            pendingVisemes = null;
          }
        }

        if (msg.type === 'visemes') {
          pendingVisemes = msg.data;
        }

        if (msg.type === 'result') {
          textsEl.innerHTML =
            `<div class="you"><span class="label">You:</span> ${escapeHtml(msg.user_text)}</div>` +
            `<div class="coach"><span class="label">Coach:</span> ${escapeHtml(msg.coach_text)}</div>`;
        }
      } else {
        // バイナリ = WAV 音声（TTS 応答）
        try {
          if (currentAudioSource) {
            currentAudioSource.onended = null;
            currentAudioSource.stop();
          }

          const audioBuffer = await audioCtx.decodeAudioData(e.data.slice(0));
          const bufferSource = audioCtx.createBufferSource();
          bufferSource.buffer = audioBuffer;
          bufferSource.connect(audioCtx.destination);
          currentAudioSource = bufferSource;

          // リップシンク開始
          if (pendingVisemes) {
            startLipSync(pendingVisemes);
            pendingVisemes = null;
          }

          bufferSource.start();

          // 再生完了で IDLE に戻す
          bufferSource.onended = () => {
            if (currentAudioSource === bufferSource) {
              currentAudioSource = null;
              stopLipSync();
              setState('IDLE');
            }
          };
        } catch (err) {
          console.error('Audio decode error:', err);
          setState('IDLE');
        }
      }
    };

    ws.onclose = () => {
      if (connected) disconnect();
    };

    connected = true;
    btn.textContent = 'Disconnect';
    btn.classList.remove('connecting');
    btn.classList.add('connected');
    btn.disabled = false;

  } catch (e) {
    console.error('Connection error:', e);
    setState('ERROR', e.message || 'Connection failed');
    disconnect();
    setTimeout(() => setState('IDLE'), 3000);
  }
}

function disconnect() {
  if (currentAudioSource) {
    currentAudioSource.onended = null;
    try { currentAudioSource.stop(); } catch (e) {}
    currentAudioSource = null;
  }
  if (workletNode) {
    workletNode.disconnect();
    workletNode = null;
  }
  if (audioCtx) {
    audioCtx.close();
    audioCtx = null;
  }
  if (micStream) {
    micStream.getTracks().forEach(t => t.stop());
    micStream = null;
  }
  if (ws) {
    ws.close();
    ws = null;
  }

  stopLipSync();
  connected = false;
  pendingVisemes = null;
  btn.textContent = 'Connect';
  btn.classList.remove('connected', 'connecting');
  btn.disabled = false;
  setState('IDLE');
}

// ===== Utilities =====
function escapeHtml(str) {
  const div = document.createElement('div');
  div.textContent = str;
  return div.innerHTML;
}
</script>
</body>
</html>
